[{"content":"Google Summer of Code - Week 3 Completed Work partial_sort The algorithm has been modified to accomodate the S/R model. Tests passed on my local end but failed on Github CI. Key Learnings The structure of hpx partitioner partition: basic partitioning function with three strategies: variable block size, static block size, and adaptive strategy partition_with_index: supporting strided partitioning, applicable to algorithms requiring index information partition_with_data: associating pre-defined data with specific block sizes, supporting more fine-grained load control static_partitioner: for synchronous execution strategies task_static_partitioner: for asynchronous execution strategies: all operations returns a future object, supports un-blocked combination of task chain, more applicble to complex asynchronous workflow How does partitioner accomodate the S/R model ExPolicy → Executor types → bulk_async_execute return types → reduce branch choosing\nNext Week Goals Improving partitioner_with_cleanup to accomodate the S/R execution model Writing tests for algorithms depending on partitioner_with_cleanup Improving related algorithms to accomodate the S/R model ","date":"2025-06-26T23:10:59+10:00","permalink":"https://sususu5.github.io/p/gsoc-week-3/","title":"GSoC Week 3"},{"content":"Google Summer of Code - Week 2 Completed Work nth_element Fixed all issues with the parallel version of nth_element All unit tests now pass Full CI pipeline passes partial_sort Analyzed the algorithm structure of partial_sort Identified key components for parallel implementation Key Learnings Technical Insight: When using just and then functions in HPX:\nInclude: #include \u0026lt;hpx/execution_base/stdexec_forward.hpp\u0026gt; Use namespace: namespace ex = hpx::execution::experimental Next Week Goals Complete the implementation fix for partial_sort and more algorithms Ensure comprehensive testing and CI compliance ","date":"2025-06-19T22:03:52+10:00","permalink":"https://sususu5.github.io/p/gsoc-week-2/","title":"GSoC Week 2"},{"content":"How to Implement a C++ Vector From Scratch Introduction std::vector is a sequence container in C++ that represents a dynamic array. It is part of the C++ Standard Template Library (STL) and provides the ability to store and manipulate a collection of elements with automatic memory management and flexible resizing.\nstd::vector is the most commonly used container in C++ development, whether you are passionate about competitive coding or interested in C++ programming, learning the low-level implementation of it helps you gain a more thorough understanding of C++ language and prepares you for better using it in the future.\nPrerequisite Knowledge Rule of Five The Rule of Five in C++ is a guideline helping developers manage resource ownership in user-defined types.\nTo be specific, if your class manages a resource, and you define any one of the following five special member functions, you should probably define all five to ensure correct behavior:\nDestructor Copy Constructor Copy Assignment Operator Move Constructor Move Assignment Operator reinterpret_cast\u0026lt;T\u0026gt;(expression) reinterpret_cast is a low-level type conversion operator in C++ used to reinterpret the binary representation of a value as a different type.\nTwo important thing about it is that it does not perform any type safety checks and it simply treats the bits of one type as if they were another.\n::operator new and ::operator delete ::operator new is a built-in global function in C++ that allocates raw, uninitialized memory on the heap.\nIt is not the same as the new expression, though the new expression uses it internally. The :: scope resolution prefix ensures you’re calling the global version of operator new, avoiding any class-specific overloads.\n::operator delete is the global deallocation function to free raw memory that was previously allocated using ::operator new.\nStep by Step Implementation Private Fields To implement a std::vector, firstly we need to define the private fields of this class.\n1 2 3 T* data_ = nullptr; // data_ is a pointer pointing to a generic type T size_t capacity_ = 0; size_t size_ = 0; Additionally, we need to define the initial size of a vector and the growth factor. The value of a growth factor is the growing rate of a vector once the capacity is full.\n1 2 static constexpr size_t startSize_ = 10; static constexpr double growthFactor_ = 1.6; // if growthFactor = 2, the vector will be doubled when it\u0026#39;s full Constructors and Destructor According to Rule of Five, we need to implement three types of constructors for out vector class, which are Default Constructor, Copy Constructor, and Move Constructor.\nIn Default Constructor, we need to allocate initial capacity memory for the underlying data and initialzie the member variables.\n1 2 3 4 Vector() { data_ = reinterpret_cast\u0026lt;T*\u0026gt;(::operator new(startSize_ * sizeof(T))); capacity_ = startSize_; } In Copy Constructor, we need to allocate capacity for a new vector and keep the input object unchanged.\n1 2 3 4 5 6 Vector(const Vector\u0026amp; other) : size_(other.size_), capacity_(other.capacity_) { data_ = reinterpret_cast\u0026lt;T*\u0026gt;(::operator new(capacity_ * sizeof(T))); for (size_t i = 0; i \u0026lt; size_; ++i) { new (data_ + i) T(other.data_[i]); } } In Move Constructor, we need to transfer the ownership of resources from one object to another instead of copying, which means the input object of this constructor should be set to void.\n1 2 3 4 5 6 Vector(Vector\u0026amp;\u0026amp; other) noexcept : data_(other.data_), capacity_(other.capacity_), size_(other.size_) { other.data_ = nullptr; other.capacity_ = 0; other.size_ = 0; } In the Destructor\n1 2 3 4 5 6 ~Vector() { for (size_t i = 0; i \u0026lt; size_; ++i) { data_[i].~T(); } ::operator delete(data_); } Assignments According to the Rule of Five, both the copy assignemnt and the move assignemnt must be implemented for this class.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // Copy assignment Vector\u0026amp; operator=(const Vector\u0026amp; other) { if (this != \u0026amp;other) { Vector temp(other); swap(temp); } return *this; } // Move assignment Vector\u0026amp; operator=(Vector\u0026amp;\u0026amp; other) noexcept { if (this != \u0026amp;other) { Vector temp(std::move(other)); swap(temp); } return *this; } Out of convenience, we can also define a specific swap function, which swaps another object with this.\n1 2 3 4 5 void swap(Vector\u0026amp; other) noexcept { std::swap(data_, other.data_); std::swap(capacity_, other.capacity_); std::swap(size_, other.size_); } Element Insertion In std::vector, the push_back method appends a new element to the end of the container and there are two versions should be implemented, which are the one handling the left value\n1 2 3 4 5 6 7 8 9 10 void push_back(const T\u0026amp; elem) { if (size_ == capacity_) { reserve(capacity_ ? static_cast\u0026lt;size_t\u0026gt;(capacity_ * growthFactor_) : startSize_); assert(size_ \u0026lt; capacity_); } assert(data_); new (data_ + size_) T(elem); ++size_; } and the one handling the right value.\n1 2 3 4 5 6 7 8 9 10 void push_back(T\u0026amp;\u0026amp; elem) { if (size_ == capacity_) { reserve(capacity_ ? static_cast\u0026lt;size_t\u0026gt;(capacity_ * growthFactor_) : startSize_); assert(size_ \u0026lt; capacity_); } assert(data_); new (data_ + size_) T(std::move(elem)); ++size_; } Element Access To allow users to access elements by index, we need to overload two versions of operator[], which handle both const and non-const objects.\n1 2 3 4 5 6 7 8 9 const T\u0026amp; operator[](size_t idx) const { assert(idx \u0026lt; size_); return data_[idx]; } T\u0026amp; operator[](size_t idx) { assert(idx \u0026lt; size_); return data_[idx]; } In addition, common operations like front, back, and size should also be added, which are\n1 2 3 4 5 6 7 8 9 10 11 12 13 const T\u0026amp; front() const { assert(size_ \u0026gt; 0); return operator[](0); } const T\u0026amp; back() const { assert(size_ \u0026gt; 0); return operator[](size_ - 1); } size_t size() const { return size_; } size_t capacity() const { return capacity_; } bool empty() const { return size_ == 0; } Element Removal \u0026amp; Container Modification There are three operations to remove elemnt from a vector, which are pop_back, erase, and clear.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 // Remove element at specific index void erase(size_t idx) { if (idx \u0026gt;= size_) return; // Destroy the element at idx data_[idx].~T(); // Move elements to fill the gap for (size_t j = idx; j \u0026lt; size_ - 1; ++j) { new (data_ + j) T(std::move(data_[j + 1])); data_[j + 1].~T(); } --size_; } // Remove all elements in the vector void clear() { for (size_t i = 0; i \u0026lt; size_; ++i) { data_[i].~T(); } size_ = 0; } // Remove an element at the back of this vector void pop_back() { if (size_ \u0026gt; 0) { --size_; data_[size_].~T(); } } Memory Management The reserve operation is used to pre-allocate memory for a container, which is useful when you know how many elements will be added to a vector.\n1 2 3 4 5 6 7 8 9 10 11 12 void reserve(size_t newCapacity) { if (capacity_ \u0026gt;= newCapacity) return; auto* newData = reinterpret_cast\u0026lt;T*\u0026gt;(::operator new(newCapacity * sizeof(T))); for (size_t i = 0; i \u0026lt; size_; ++i) { new (newData + i) T(std::move(data_[i])); data_[i].~T(); } ::operator delete(data_); data_ = newData; capacity_ = newCapacity; } Complete Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 #include \u0026lt;cstddef\u0026gt; #include \u0026lt;cassert\u0026gt; #include \u0026lt;cstdlib\u0026gt; #include \u0026lt;utility\u0026gt; #include \u0026lt;new\u0026gt; #include \u0026lt;vector\u0026gt; template \u0026lt;typename T\u0026gt; class Vector { public: // Default constructor Vector() { data_ = reinterpret_cast\u0026lt;T*\u0026gt;(::operator new(startSize_ * sizeof(T))); capacity_ = startSize_; } // Copy constructor Vector(const Vector\u0026amp; other) : size_(other.size_), capacity_(other.capacity_) { data_ = reinterpret_cast\u0026lt;T*\u0026gt;(::operator new(capacity_ * sizeof(T))); for (size_t i = 0; i \u0026lt; size_; ++i) { new (data_ + i) T(other.data_[i]); } } // Move constructor Vector(Vector\u0026amp;\u0026amp; other) noexcept : data_(other.data_), capacity_(other.capacity_), size_(other.size_) { other.data_ = nullptr; other.capacity_ = 0; other.size_ = 0; } // Copy assignment Vector\u0026amp; operator=(const Vector\u0026amp; other) { if (this != \u0026amp;other) { Vector temp(other); swap(temp); } return *this; } // Move assignment Vector\u0026amp; operator=(Vector\u0026amp;\u0026amp; other) noexcept { if (this != \u0026amp;other) { Vector temp(std::move(other)); swap(temp); } return *this; } // Destructor ~Vector() { for (size_t i = 0; i \u0026lt; size_; ++i) { data_[i].~T(); } ::operator delete(data_); } // Left value reference void push_back(const T\u0026amp; elem) { if (size_ == capacity_) { reserve(capacity_ ? static_cast\u0026lt;size_t\u0026gt;(capacity_ * growthFactor_) : startSize_); assert(size_ \u0026lt; capacity_); } assert(data_); new (data_ + size_) T(elem); // Fixed: construct at correct position with elem ++size_; } // Right value reference void push_back(T\u0026amp;\u0026amp; elem) { if (size_ == capacity_) { reserve(capacity_ ? static_cast\u0026lt;size_t\u0026gt;(capacity_ * growthFactor_) : startSize_); assert(size_ \u0026lt; capacity_); } assert(data_); new (data_ + size_) T(std::move(elem)); ++size_; } // Const value overload const T\u0026amp; operator[](size_t idx) const { assert(idx \u0026lt; size_); return data_[idx]; } // Non-const value overload T\u0026amp; operator[](size_t idx) { assert(idx \u0026lt; size_); return data_[idx]; } const T\u0026amp; front() const { assert(size_ \u0026gt; 0); return operator[](0); } const T\u0026amp; back() const { assert(size_ \u0026gt; 0); return operator[](size_ - 1); } size_t size() const { return size_; } size_t capacity() const { return capacity_; } bool empty() const { return size_ == 0; } void reserve(size_t newCapacity) { if (capacity_ \u0026gt;= newCapacity) return; auto* newData = reinterpret_cast\u0026lt;T*\u0026gt;(::operator new(newCapacity * sizeof(T))); for (size_t i = 0; i \u0026lt; size_; ++i) { new (newData + i) T(std::move(data_[i])); data_[i].~T(); } ::operator delete(data_); data_ = newData; capacity_ = newCapacity; } void erase(size_t idx) { if (idx \u0026gt;= size_) return; // Destroy the element at idx data_[idx].~T(); // Move elements to fill the gap for (size_t j = idx; j \u0026lt; size_ - 1; ++j) { new (data_ + j) T(std::move(data_[j + 1])); data_[j + 1].~T(); } --size_; } void clear() { for (size_t i = 0; i \u0026lt; size_; ++i) { data_[i].~T(); } size_ = 0; } void pop_back() { if (size_ \u0026gt; 0) { --size_; data_[size_].~T(); } } private: void swap(Vector\u0026amp; other) noexcept { std::swap(data_, other.data_); std::swap(capacity_, other.capacity_); std::swap(size_, other.size_); } T* data_ = nullptr; size_t capacity_ = 0; size_t size_ = 0; static constexpr size_t startSize_ = 10; static constexpr double growthFactor_ = 1.6; }; int main() { Vector\u0026lt;int\u0026gt; v; assert(v.size() == 0); for (int i = 0; i \u0026lt; 100; ++i) v.push_back(i); for (int i = 0; i \u0026lt; 100; ++i) assert(v[i] == i); assert(v.size() == 100); for (int i = 0; i \u0026lt; 50; ++i) { assert(v[0] == i); v.erase(0); } assert(v.size() == 50); for (int i = 50; i \u0026lt; 100; ++i) { assert(v[0] == i); v.erase(0); } assert(v.size() == 0); Vector\u0026lt;int\u0026gt; v2; v2.push_back(42); assert(v2.front() == 42); assert(v2.back() == 42); Vector\u0026lt;int\u0026gt; v3 = v2; assert(v3.size() == 1); assert(v3[0] == 42); return 0; } ","date":"2025-06-11T13:51:00+10:00","permalink":"https://sususu5.github.io/p/how-to-implement-a-c-vector-from-scratch/","title":"How to Implement a C++ Vector From Scratch"},{"content":"How to design a POI (Point of Interest) Service Functional Requirements Searching nearby locations Viewing details Owners can edit / delete Non-functional Requirements Latency: 1s Freshness: 1 day -\u0026gt; 1 hour Scalability Fault Tolerance Assumptions 1B users -\u0026gt; 50% -\u0026gt; 500M DAU 200M businesses Storage: NoSQL, SQL, in memory Database Selection In-memory: using multiple machines to shard the data, and the latency requirement is 1s, it\u0026rsquo;s expensive to use this SQL: more expensive NoSQL: cheaper, fast querying, self-sharding and optimization, suitable How to scale searching Master-Slave Model, separate reading and writing This system is suitable for using this model because the need for reading is much more than writing Not using whole table scaning here, given longtitude and latitude Composite Index can not speed up the searching here because it follows the Leftmost Prefix Rule, we can only search the range of the latitude once the longitude is matched, so it equals whole table scaning Two other effective searching ways will be introduced in the following content GeoHash GeoHash is a spatial hashing algorithm that continuously divides latitude and longitude ranges in half (using a Z-order curve), converting a (latitude, longitude) pair into a Base32 string that represents the geographic grid cell in which the location falls It is a value stored in the database The longer the string, the higher the precision of the geographical location Quad Tree A Quad Tree is a tree data structure that recursively partitions a two-dimensional space into four quadrants (subregions). Each node in the tree has up to four children representing the top-left, top-right, bottom-left, and bottom-right regions It is a memory structure Quad Tree can be used as indicies to speed up the searching (k values), assume each node contains about 100 businesses Can it fits into memory? (business_id, latitude, longitute, short_brief) \u0026lt; 50B (200M / 100) * (100 * 50B) = 10GB, which can be stored in memory, meets the latency requirement in 1 second\nHow to build this tree? Need a starting point, stored on disk as a seed value\nHow to update this tree? Live update / eventually consistecy\nAdding a cache to store the latitude, longitude, and their corresponding business list, extra cost.\nConstruct the Quad Tree according to the deployment (west, middle, east USA), extra cost, availability\n","date":"2025-06-07T11:43:38+10:00","permalink":"https://sususu5.github.io/p/how-to-design-a-poi-point-of-interest-service/","title":"How to Design a POI (Point of Interest) Service"},{"content":"Google Summer of Code Week 1 Completed work The modifications proposed in the proposal have been applied to the parallel version of nth_element, but the unit test still didn\u0026rsquo;t pass. According to the error messages, the reason behind the failure is that the type returned by the partition function is a sender, which is not a future expected by the partition_iter. A specific implementation is planned to be added for the parallel version of the nth_element to accommodate the Senders/Receivers mode. Learnings Got a deeper understanding of the algorithms structure by reading the codebase. (tag_parallel_algorithm wrapper -\u0026gt; algorithm wrapper -\u0026gt; sequential / parallel implementation) Definitions of some basic modes of parallel algorithms. (reduce, scan, copy, map) The parallel version of the nth_element algorithm uses partition rather than using a partitioner, which means certain proposed amendments from last year\u0026rsquo;s report might not be relevant anymore. Plan for Next Week Complete the fix of the nth_element, and the pull request should be merged. Start the fix for the next algorithm, the proposed one is partial_sort, which may be further discussed. ","date":"2025-06-05T13:30:27+10:00","permalink":"https://sususu5.github.io/p/gsoc-week-1/","title":"GSoC Week 1"},{"content":"How to design a TikTok Functional Requirements Video Upload: Allow users to upload videos to the platform. Video Playback: Enable users to watch videos. By developing these, we can construct a minimum viable product.\nNon-functional Requirements Scalability: Support a massive user base with high concurrency. Availability: Ensure the system remains operational even during partial failures. Low Latency: Minimize delays in video loading and playback. Fault Tolerance: Handle hardware/network failures gracefully without data loss. Assumptions User Base: 1 billion daily active users (DAU). Usage Patterns: Each user watches 100 videos per day. Each user uploads 1 video per day. Video Size: Average video size is 10MB. Database Selection: SQL vs NoSQL SQL Databases: Pros: Strong consistency, relational data support. Cons: Challenges with sharding and hotspot management. NoSQL Databases: Pros: Cost-effective, horizontally scalable. Cons: Limited transactional support. Video Storage Strategy Blob Storage (Binary Large Object):\nOptimized for unstructured data (videos, images, audio). Ideal for storing and retrieving large volumes of small files efficiently. How to upload a video Since we don\u0026rsquo;t know what users are uploading, exposing the storage to the interface directly is unsafe. A better option is allocating a temporary space to store the original videos uploaded by users. When uploading, a video can be cut into small pieces to support breakpoint resume upload when a break happens, and also parallel uploading, which means multiple segments can be uploaded simultaneously. (for a mobile app, the network environment is not stable) Once all segments are uploaded, we can use a message queue and a worker pool to merge all the segments and do a file integrity verification. After that, this video should be encoded into different formats because videos of different qualities should be played according to devices and network. How to watch a video To avoid hotspots caused by frequent access to popular videos, we can deploy a CDN near user locations to offload traffic from the blob storage. Although storing videos in a CDN speeds up delivery and reduces latency, it also comes with high costs. So, we should make sure only the most popular videos are cached there. By introducing an extractor service, it can regularly find popular videos from the blob storage and send them to the CDN, those outdated videos are replaced. We can also introduce a streaming protocol like the HTTP Live Streaming from Apple to realize \u0026ldquo;stream-as-you-go\u0026rdquo; manner, which improves user experience. Show off We can introduce a recommendation system to recommend videos to users rather than pushing original feed accoring to the time. We can introduce a Two-Tower Model to embed user and video features into separate vectors. When a client requests videos, the system can recommend those that match their interests based on vector similarity. The pro is the vieo watching time of clients can be extended, the con is the extra cost of hiring a team to construct and deploy the model. ","date":"2025-06-03T16:18:56+10:00","permalink":"https://sususu5.github.io/p/how-to-design-a-tiktok/","title":"How to Design a TikTok"},{"content":"System Design Basic 2 SQL vs NoSQL SQL (Relational Databases) Key Examples: MySQL, PostgreSQL, Oracle Core Philosophy: Structured, Strong Consistency, and Transactions When to choose: Fixed \u0026amp; Complex Data Schema:\nE-commerce Orders: Requires Strong Consistency (ACID Transactions):\nNoSQL (Non-Relational Databases) Key Examples: MongoDB (Document), Redis (Key-Value), Cassandra (Columnar) Core Philosophy: High Scalability, Flexibility, and Performance，usually accepts Eventual Consistency When to choose: Flexible or Evolving Data Schema:\nNeeds Extremely High Read/Write Throughput \u0026amp; Massive Data Storage:\nRequires High Availability (Fault Tolerance) \u0026amp; Distributed Nature:\nEventual Consistency is Acceptable:\nScale Up vs Scale Out Scale Up (Vertical Scaling) Definition: Adding more power to an existing machine Situation: Startup or simple app, performance bottleneck on one machine (short term) Scale Out (Horizontal Scaling) Definition: Adding more machines to the system Situation: High-traffic web application, cloud-native or containerized systems ","date":"2025-05-26T20:51:24+08:00","permalink":"https://sususu5.github.io/p/system-design-basic-2/","title":"System Design Basic 2"},{"content":"System Design Basic 1 CAP Theorem Any distributed system cannot simultaneously guarantee all three of the following properties:\nConsistency\nAll nodes see the same data at the same time All replicas in the system remain synchronized Availability\nThe system remains operational even when some nodes fail Every request receives a response (whether success or failure) Partition Tolerance\nThe system continues to operate despite network partitions (communication breakdowns between nodes) The system functions normally even when messages are lost or delayed Consistency Models Strong Consistency Models\nLinearizability: The strongest consistency guarantee, where the system behaves as if there\u0026rsquo;s only one copy of data, with all operations having a global execution order.\nProvides real-time guarantees Highest performance overhead Use Cases: Financial transaction systems, inventory management Sequential Consistency: All processes see the same order of operations, but it doesn\u0026rsquo;t need to correspond to real-time ordering.\nSlightly weaker than linearizability but more efficient Guarantees consistent global operation ordering Allows some latency Causal Consistency: Only guarantees that causally related operations execute in the same order across all nodes.\nWeaker than sequential consistency but more practical Allows different ordering of concurrent operations Maintains logical dependencies Weak Consistency Models\nEventual Consistency: The system guarantees that all replicas will eventually converge to the same state when no new updates occur.\nHigh availability and performance Allows temporary inconsistencies Requires conflict resolution mechanisms Use Cases: DNS systems, social media feeds, shopping carts Session Consistency: Guarantees consistency within a single session, ensuring users see monotonic data within their session.\nRead-your-writes: Users can see their own writes Monotonic reads: Won\u0026rsquo;t read older data Monotonic writes: Write operations execute in order Partition Tolerance Implementation Strategies\nData Replication: Maintaining copies across multiple nodes Sharding: Distributing data across different nodes Correctness Protocols: Using Paxos, Raft for consistency Failure Detection: Promptly identifying partition issues Recovery Mechanisms\nAnti-entropy: Data synchronization after partition healing Read Repair: Fixing inconsistencies during reads Design Patterns\nLeader Election: Re-establishing primary nodes after partition Read/Write Quorums: Setting R + W \u0026gt; N for consistency ","date":"2025-05-23T21:35:58+08:00","permalink":"https://sususu5.github.io/p/system-design-basic-1/","title":"System Design Basic 1"}]