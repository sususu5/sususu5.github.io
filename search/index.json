[{"content":"How to design a POI (Point of Interest) Service Functional Requirements Searching nearby locations Viewing details Owners can edit / delete Non-functional Requirements Latency: 1s Freshness: 1 day -\u0026gt; 1 hour Scalability Fault Tolerance Assumptions 1B users -\u0026gt; 50% -\u0026gt; 500M DAU 200M businesses Storage: NoSQL, SQL, in memory Database Selection In-memory: using multiple machines to shard the data, and the latency requirement is 1s, it\u0026rsquo;s expensive to use this SQL: more expensive NoSQL: cheaper, fast querying, self-sharding and optimization, suitable How to scale searching Master-Slave Model, separate reading and writing This system is suitable for using this model because the need for reading is much more than writing Not using whole table scaning here, given longtitude and latitude Composite Index can not speed up the searching here because it follows the Leftmost Prefix Rule, we can only search the range of the latitude once the longitude is matched, so it equals whole table scaning Two other effective searching ways will be introduced in the following content GeoHash GeoHash is a spatial hashing algorithm that continuously divides latitude and longitude ranges in half (using a Z-order curve), converting a (latitude, longitude) pair into a Base32 string that represents the geographic grid cell in which the location falls It is a value stored in the database The longer the string, the higher the precision of the geographical location Quad Tree A Quad Tree is a tree data structure that recursively partitions a two-dimensional space into four quadrants (subregions). Each node in the tree has up to four children representing the top-left, top-right, bottom-left, and bottom-right regions It is a memory structure Quad Tree can be used as indicies to speed up the searching (k values), assume each node contains about 100 businesses Can it fits into memory? (business_id, latitude, longitute, short_brief) \u0026lt; 50B (200M / 100) * (100 * 50B) = 10GB, which can be stored in memory, meets the latency requirement in 1 second\nHow to build this tree? Need a starting point, stored on disk as a seed value\nHow to update this tree? Live update / eventually consistecy\nAdding a cache to store the latitude, longitude, and their corresponding business list, extra cost.\nConstruct the Quad Tree according to the deployment (west, middle, east USA), extra cost, availability\n","date":"2025-06-07T11:43:38+10:00","permalink":"https://sususu5.github.io/p/how-to-design-a-poi-point-of-interest-service/","title":"How to Design a POI (Point of Interest) Service"},{"content":"Google Summer of Code Week 1 Completed work The modifications proposed in the proposal have been applied to the parallel version of nth_element, but the unit test still didn\u0026rsquo;t pass. According to the error messages, the reason behind the failure is that the type returned by the partition function is a sender, which is not a future expected by the partition_iter. A specific implementation is planned to be added for the parallel version of the nth_element to accommodate the Senders/Receivers mode. Learnings Got a deeper understanding of the algorithms structure by reading the codebase. (tag_parallel_algorithm wrapper -\u0026gt; algorithm wrapper -\u0026gt; sequential / parallel implementation) Definitions of some basic modes of parallel algorithms. (reduce, scan, copy, map) The parallel version of the nth_element algorithm uses partition rather than using a partitioner, which means certain proposed amendments from last year\u0026rsquo;s report might not be relevant anymore. Plan for Next Week Complete the fix of the nth_element, and the pull request should be merged. Start the fix for the next algorithm, the proposed one is partial_sort, which may be further discussed. ","date":"2025-06-05T13:30:27+10:00","permalink":"https://sususu5.github.io/p/gsoc-week-1/","title":"GSoC Week 1"},{"content":"How to design a TikTok Functional Requirements Video Upload: Allow users to upload videos to the platform. Video Playback: Enable users to watch videos. By developing these, we can construct a minimum viable product.\nNon-functional Requirements Scalability: Support a massive user base with high concurrency. Availability: Ensure the system remains operational even during partial failures. Low Latency: Minimize delays in video loading and playback. Fault Tolerance: Handle hardware/network failures gracefully without data loss. Assumptions User Base: 1 billion daily active users (DAU). Usage Patterns: Each user watches 100 videos per day. Each user uploads 1 video per day. Video Size: Average video size is 10MB. Database Selection: SQL vs NoSQL SQL Databases: Pros: Strong consistency, relational data support. Cons: Challenges with sharding and hotspot management. NoSQL Databases: Pros: Cost-effective, horizontally scalable. Cons: Limited transactional support. Video Storage Strategy Blob Storage (Binary Large Object):\nOptimized for unstructured data (videos, images, audio). Ideal for storing and retrieving large volumes of small files efficiently. How to upload a video Since we don\u0026rsquo;t know what users are uploading, exposing the storage to the interface directly is unsafe. A better option is allocating a temporary space to store the original videos uploaded by users. When uploading, a video can be cut into small pieces to support breakpoint resume upload when a break happens, and also parallel uploading, which means multiple segments can be uploaded simultaneously. (for a mobile app, the network environment is not stable) Once all segments are uploaded, we can use a message queue and a worker pool to merge all the segments and do a file integrity verification. After that, this video should be encoded into different formats because videos of different qualities should be played according to devices and network. How to watch a video To avoid hotspots caused by frequent access to popular videos, we can deploy a CDN near user locations to offload traffic from the blob storage. Although storing videos in a CDN speeds up delivery and reduces latency, it also comes with high costs. So, we should make sure only the most popular videos are cached there. By introducing an extractor service, it can regularly find popular videos from the blob storage and send them to the CDN, those outdated videos are replaced. We can also introduce a streaming protocol like the HTTP Live Streaming from Apple to realize \u0026ldquo;stream-as-you-go\u0026rdquo; manner, which improves user experience. Show off We can introduce a recommendation system to recommend videos to users rather than pushing original feed accoring to the time. We can introduce a Two-Tower Model to embed user and video features into separate vectors. When a client requests videos, the system can recommend those that match their interests based on vector similarity. The pro is the vieo watching time of clients can be extended, the con is the extra cost of hiring a team to construct and deploy the model. ","date":"2025-06-03T16:18:56+10:00","permalink":"https://sususu5.github.io/p/how-to-design-a-tiktok/","title":"How to Design a TikTok"},{"content":"System Design Basic 2 SQL vs NoSQL SQL (Relational Databases) Key Examples: MySQL, PostgreSQL, Oracle Core Philosophy: Structured, Strong Consistency, and Transactions When to choose: Fixed \u0026amp; Complex Data Schema:\nE-commerce Orders: Requires Strong Consistency (ACID Transactions):\nNoSQL (Non-Relational Databases) Key Examples: MongoDB (Document), Redis (Key-Value), Cassandra (Columnar) Core Philosophy: High Scalability, Flexibility, and Performanceï¼Œusually accepts Eventual Consistency When to choose: Flexible or Evolving Data Schema:\nNeeds Extremely High Read/Write Throughput \u0026amp; Massive Data Storage:\nRequires High Availability (Fault Tolerance) \u0026amp; Distributed Nature:\nEventual Consistency is Acceptable:\nScale Up vs Scale Out Scale Up (Vertical Scaling) Definition: Adding more power to an existing machine Situation: Startup or simple app, performance bottleneck on one machine (short term) Scale Out (Horizontal Scaling) Definition: Adding more machines to the system Situation: High-traffic web application, cloud-native or containerized systems ","date":"2025-05-26T20:51:24+08:00","permalink":"https://sususu5.github.io/p/system-design-basic-2/","title":"System Design Basic 2"},{"content":"System Design Basic 1 CAP Theorem Any distributed system cannot simultaneously guarantee all three of the following properties:\nConsistency\nAll nodes see the same data at the same time All replicas in the system remain synchronized Availability\nThe system remains operational even when some nodes fail Every request receives a response (whether success or failure) Partition Tolerance\nThe system continues to operate despite network partitions (communication breakdowns between nodes) The system functions normally even when messages are lost or delayed Consistency Models Strong Consistency Models\nLinearizability: The strongest consistency guarantee, where the system behaves as if there\u0026rsquo;s only one copy of data, with all operations having a global execution order.\nProvides real-time guarantees Highest performance overhead Use Cases: Financial transaction systems, inventory management Sequential Consistency: All processes see the same order of operations, but it doesn\u0026rsquo;t need to correspond to real-time ordering.\nSlightly weaker than linearizability but more efficient Guarantees consistent global operation ordering Allows some latency Causal Consistency: Only guarantees that causally related operations execute in the same order across all nodes.\nWeaker than sequential consistency but more practical Allows different ordering of concurrent operations Maintains logical dependencies Weak Consistency Models\nEventual Consistency: The system guarantees that all replicas will eventually converge to the same state when no new updates occur.\nHigh availability and performance Allows temporary inconsistencies Requires conflict resolution mechanisms Use Cases: DNS systems, social media feeds, shopping carts Session Consistency: Guarantees consistency within a single session, ensuring users see monotonic data within their session.\nRead-your-writes: Users can see their own writes Monotonic reads: Won\u0026rsquo;t read older data Monotonic writes: Write operations execute in order Partition Tolerance Implementation Strategies\nData Replication: Maintaining copies across multiple nodes Sharding: Distributing data across different nodes Correctness Protocols: Using Paxos, Raft for consistency Failure Detection: Promptly identifying partition issues Recovery Mechanisms\nAnti-entropy: Data synchronization after partition healing Read Repair: Fixing inconsistencies during reads Design Patterns\nLeader Election: Re-establishing primary nodes after partition Read/Write Quorums: Setting R + W \u0026gt; N for consistency ","date":"2025-05-23T21:35:58+08:00","permalink":"https://sususu5.github.io/p/system-design-basic-1/","title":"System Design Basic 1"}]